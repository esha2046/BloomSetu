import streamlit as st
import time
from datetime import datetime
import io

from config import API_avai, REQUEST_COOLDOWN, MIN_CONTENT_LENGTH, DAILY_LIMIT, OPTIMAL_CONTENT_LENGTH, MAX_IMAGE_SIZE_KB
from extract import extract_pdf, extract_docx
from question_generator import generate_questions
from evaluate import evaluate_answer, calculate_total_score
from curriculum import BOARDS, CLASSES, ALL_SUBJECTS, QUESTION_TYPES, get_chapters, get_keywords_for_bloom
from shared_state import save_questions, load_questions, save_student_result, load_student_history
from auth import login_page, register_page, logout, check_auth, init_users


# Initialize
init_users()

st.set_page_config(
    page_title="BloomSetu",
    layout="wide",
    page_icon="üéì"
)

# Check authentication
if not check_auth():
    if st.session_state.get('show_register', False):
        register_page()
    else:
        login_page()
    st.stop()

# Initialize session state
def init_session_state():
    defaults = {
        'questions': [],
        'student_answers': {},
        'results': None,
        'last_request_time': 0,
        'extracted_content': "",
        'extracted_images': [],
        'board': 'CBSE',
        'class_level': 10,
        'subject': 'Physics',
        'chapter': '',
        'question_type': 'MCQ',
        'bloom_level': 'Apply',
        'quota_data': {'count': 0, 'date': datetime.now().date()}
    }
    for key, value in defaults.items():
        if key not in st.session_state:
            st.session_state[key] = value

def init_quota_tracking():
    today = datetime.now().date()
    if st.session_state.quota_data['date'] != today:
        st.session_state.quota_data['count'] = 0
        st.session_state.quota_data['date'] = today

def check_quota():
    if not API_avai:
        return True
    return st.session_state.quota_data['count'] < DAILY_LIMIT

def increment_quota():
    st.session_state.quota_data['count'] += 1

def can_make_request():
    elapsed = time.time() - st.session_state.last_request_time
    if elapsed < REQUEST_COOLDOWN:
        st.warning(f"Please wait {REQUEST_COOLDOWN - elapsed:.1f}s")
        return False
    st.session_state.last_request_time = time.time()
    return True

init_session_state()
init_quota_tracking()

# Header with logout
col1, col2 = st.columns([6, 1])
with col1:
    role_icon = "üë®‚Äçüè´" if st.session_state.role == "teacher" else "üë®‚Äçüéì"
    st.title(f"{role_icon} BloomSetu - {st.session_state.role.title()} Dashboard")
    st.caption(f"Welcome, {st.session_state.username}!")
with col2:
    st.write("")
    st.write("")
    if st.button("üö™ Logout", use_container_width=True):
        logout()

st.divider()

# Sidebar
with st.sidebar:
    st.markdown("### Curriculum Settings")
    board = st.selectbox("Board", BOARDS, index=BOARDS.index(st.session_state.board))
    st.session_state.board = board

    class_level = st.selectbox(
        "Class",
        CLASSES,
        index=CLASSES.index(st.session_state.class_level)
        if st.session_state.class_level in CLASSES else 4
    )
    st.session_state.class_level = class_level

    subject = st.selectbox(
        "Subject",
        ALL_SUBJECTS,
        index=ALL_SUBJECTS.index(st.session_state.subject)
        if st.session_state.subject in ALL_SUBJECTS else 0
    )
    st.session_state.subject = subject

    chapters = get_chapters(subject, class_level)
    if chapters:
        chapter_options = ["All Chapters"] + chapters
        chapter = st.selectbox("Chapter", chapter_options)
        st.session_state.chapter = "" if chapter == "All Chapters" else chapter
    else:
        chapter = st.text_input("Chapter or Topic", value=st.session_state.chapter)
        st.session_state.chapter = chapter

    st.divider()
    st.success("API Connected" if API_avai else "Demo Mode")

    st.divider()
    st.markdown("### Statistics")
    
    if st.session_state.role == "teacher":
        st.metric("Questions Generated", len(st.session_state.questions))
        if API_avai:
            remaining = DAILY_LIMIT - st.session_state.quota_data['count']
            st.metric("API Calls Today", f"{remaining}/{DAILY_LIMIT}")
        
        history = load_student_history()
        st.metric("Student Assessments", len(history))
        if history:
            avg_score = sum(h['percentage'] for h in history) / len(history)
            st.metric("Class Average", f"{avg_score:.1f}%")
    else:
        history = load_student_history()
        my_history = [h for h in history if h.get('username') == st.session_state.username]
        st.metric("Assessments Taken", len(my_history))
        if my_history:
            avg_score = sum(h['percentage'] for h in my_history) / len(my_history)
            st.metric("Average Score", f"{avg_score:.1f}%")

# TEACHER INTERFACE
if st.session_state.role == "teacher":
    tab1, tab2 = st.tabs(["üìù Create Assessment", "üìä Student Analytics"])

    with tab1:
        col1, col2 = st.columns([2, 1])

        with col1:
            st.subheader("Input Study Material")
            input_method = st.radio(
                "Choose input method:",
                ["Text", "File Upload"],
                horizontal=True
            )

            content = ""
            if input_method == "Text":
                content = st.text_area(
                    "Paste study material:",
                    height=250,
                    value=st.session_state.extracted_content,
                    placeholder="Enter educational content..."
                )
            else:
                uploaded_file = st.file_uploader("Upload PDF or DOCX", type=['pdf', 'docx'])
                if uploaded_file:
                    with st.spinner("Extracting text..."):
                        if uploaded_file.name.endswith('.pdf'):
                            content, images = extract_pdf(uploaded_file)
                            st.session_state.extracted_images = images
                        else:
                            content = extract_docx(uploaded_file)
                            st.session_state.extracted_images = []
                        if not content:
                            content = ""
                    if content:
                        st.session_state.extracted_content = content
                        with st.expander("Preview"):
                            st.text(content[:1500] + ("..." if len(content) > 1500 else ""))
                            if st.session_state.get('extracted_images'):
                                st.image(st.session_state.extracted_images, caption=[f"Image {i+1}" for i in range(len(st.session_state.extracted_images))])
                        st.success(f"Extracted {len(content)} characters" + (f" and {len(st.session_state.extracted_images)} images" if st.session_state.get('extracted_images') else ""))

        with col2:
            st.subheader("Question Settings")
            q_type = st.selectbox(
                "Question Type",
                list(QUESTION_TYPES.keys()),
                format_func=lambda x: f"{QUESTION_TYPES[x]['name']} ({QUESTION_TYPES[x]['marks']} marks)"
            )

            type_info = QUESTION_TYPES[q_type]
            st.info(type_info['description'])

            if 'word_limit' in type_info:
                st.caption(f"Word Limit: {type_info['word_limit']}")

            num_questions = st.slider("Number of Questions", 1, 10, 3)

            bloom_level = st.selectbox(
                "Bloom's Taxonomy Level",
                ["Remember", "Understand", "Apply", "Analyze", "Evaluate", "Create"]
            )

            keywords = get_keywords_for_bloom(bloom_level)
            st.caption(f"Keywords: {', '.join(keywords[:3])}")

        st.divider()

        col_left, col_center, col_right = st.columns([1, 2, 1])
        with col_center:
            if st.button("üéØ Generate Assessment", type="primary", use_container_width=True):
                if not content:
                    st.error("Please provide study material")
                elif len(content) < MIN_CONTENT_LENGTH:
                    st.error(f"Content too short (minimum {MIN_CONTENT_LENGTH} characters)")
                elif not can_make_request():
                    st.stop()
                elif API_avai and not check_quota():
                    st.error(f"Daily limit reached ({DAILY_LIMIT} assessments). Using demo mode.")
                else:
                    # Show optimization warnings
                    images = st.session_state.get('extracted_images', [])
                    warnings = []
                    
                    if len(content) > OPTIMAL_CONTENT_LENGTH:
                        reduction = len(content) - OPTIMAL_CONTENT_LENGTH
                        warnings.append(f"üìù Content will be optimized ({reduction} chars will be trimmed)")
                    
                    if images and q_type in ['IMAGE', 'DIAGRAM']:
                        # Estimate image sizes
                        try:
                            img_sizes = []
                            for img in images[:1]:
                                img_bytes = io.BytesIO()
                                img.save(img_bytes, format='JPEG')
                                img_sizes.append(len(img_bytes.getvalue()) / 1024)
                            if img_sizes:
                                max_img_size = max(img_sizes)
                                if max_img_size > MAX_IMAGE_SIZE_KB:
                                    warnings.append(f"üñºÔ∏è Images will be compressed (target: <{MAX_IMAGE_SIZE_KB}KB each)")
                                warnings.append(f"üñºÔ∏è {len(images[:1])} image(s) will be sent to API")
                        except:
                            warnings.append(f"üñºÔ∏è {len(images[:1])} image(s) will be sent to API")
                    elif images and q_type not in ['IMAGE', 'DIAGRAM']:
                        warnings.append(f"‚ÑπÔ∏è {len(images)} image(s) extracted but won't be sent (not needed for {q_type})")
                    
                    if warnings and API_avai:
                        with st.expander("‚ö° Optimization Info", expanded=False):
                            for warning in warnings:
                                st.info(warning)
                    
                    curriculum_info = {
                        'board': st.session_state.board,
                        'class': st.session_state.class_level,
                        'subject': st.session_state.subject,
                        'chapter': st.session_state.chapter,
                        'num_questions': num_questions,
                        'question_type': q_type,
                        'bloom_level': bloom_level
                    }

                    with st.spinner("Generating questions..."):
                        was_using_api = API_avai and check_quota()
                        images = st.session_state.get('extracted_images', [])
                        questions = generate_questions(content, curriculum_info, images)
                        if questions and was_using_api:
                            increment_quota()

                    if questions:
                        st.session_state.questions = questions
                        # Ensure images are preserved in session state
                        if images:
                            st.session_state.extracted_images = images
                        st.success(f"‚úÖ Generated {len(questions)} questions")

        if st.session_state.questions:
            st.divider()
            st.subheader("Generated Assessment")

            q = st.session_state.questions[0]
            st.info(
                f"{q['board']} | Class {q['class']} | {q['subject']} "
                f"{'| ' + q['chapter'] if q['chapter'] else ''}"
            )

            total_marks = sum(q.get('marks', 1) for q in st.session_state.questions)
            st.caption(f"Total Marks: {total_marks}")

            for idx, question in enumerate(st.session_state.questions, 1):
                marks = question.get('marks', 1)
                with st.expander(
                    f"Q{idx} ({marks} marks): {question['question'][:70]}...",
                    expanded=(idx == 1)
                ):
                    st.markdown(question['question'])
                    
                    # Display image if available
                    images = st.session_state.get('extracted_images', [])
                    if images:
                        # Check if this question should have an image
                        img_idx = question.get('image_index', 0)
                        should_show_image = False
                        
                        # Check various conditions for showing image
                        if question.get('has_image') or question.get('image_index') is not None:
                            should_show_image = True
                        # Check if question mentions diagram/figure/image
                        elif any(keyword in question.get('question', '').lower() for keyword in ['diagram', 'figure', 'image', 'observe', 'shown']):
                            should_show_image = True
                        
                        if should_show_image and img_idx < len(images):
                            st.image(images[img_idx], caption=f"Diagram/Image for Question {idx}", use_container_width=True)

                    if question.get('ncert_reference'):
                        st.caption(question['ncert_reference'])

                    if 'options' in question:
                        for key, value in question['options'].items():
                            st.markdown(f"{key}) {value}")
                        st.success(f"‚úì Correct Answer: {question['correct_answer']}")
                        st.info(f"üí° {question['explanation']}")
                    elif 'labels' in question:
                        st.markdown("**Correct Labels**")
                        for label_key, label_name in question['labels'].items():
                            st.markdown(f"**{label_key}**: {label_name}")
                        st.markdown("**Model Answer**")
                        st.write(question['model_answer'])
                        st.markdown("**Key Points**")
                        for point in question['key_points']:
                            st.markdown(f"- {point}")
                    else:
                        st.markdown("**Model Answer**")
                        st.write(question['model_answer'])

                        st.markdown("**Key Points**")
                        for point in question['key_points']:
                            st.markdown(f"- {point}")

                        if 'marking_scheme' in question:
                            st.markdown("**Marking Scheme**")
                            for scheme in question['marking_scheme']:
                                st.markdown(f"- {scheme}")

            st.divider()
            col1, col2 = st.columns(2)
            with col1:
                if st.button("üì§ Publish to Students", type="primary", use_container_width=True):
                    if save_questions(st.session_state.questions):
                        st.success("‚úÖ Assessment published! Students can access it now.")
                    else:
                        st.error("Failed to publish")
            with col2:
                if st.button("üóëÔ∏è Clear", use_container_width=True):
                    st.session_state.questions = []
                    st.rerun()

    with tab2:
        st.subheader("Student Performance Analytics")
        history = load_student_history()
        
        if history:
            col1, col2, col3 = st.columns(3)

            avg_score = sum(h['percentage'] for h in history) / len(history)
            col1.metric("Total Assessments", len(history))
            col2.metric("Class Average", f"{avg_score:.1f}%")
            col3.metric("Latest Score", f"{history[-1]['percentage']:.1f}%")

            st.divider()
            st.markdown("### Recent Submissions")

            for idx, attempt in enumerate(reversed(history[-10:]), 1):
                username = attempt.get('username', 'Anonymous')
                with st.expander(
                    f"{username} - {attempt['percentage']:.1f}% ({attempt['timestamp']})"
                ):
                    col_a, col_b = st.columns(2)
                    with col_a:
                        st.write(f"üìÖ Date: {attempt['timestamp']}")
                        st.write(f"üìù Questions: {attempt['num_questions']}")
                    with col_b:
                        st.write(f"‚úÖ Score: {attempt['total_score']:.1f}/{attempt['max_score']}")
                        st.write(f"üìä Percentage: {attempt['percentage']:.1f}%")
        else:
            st.info("No student submissions yet")

# STUDENT INTERFACE
else:
    questions = load_questions()
    if questions and not st.session_state.questions:
        st.session_state.questions = questions
        st.session_state.student_answers = {}
        st.session_state.results = None
        # Try to preserve images if they exist in session state
        # (Images should be in session state from when teacher generated questions)

    if not st.session_state.questions:
        st.warning("‚è≥ No assessment available")
        st.info("üë®‚Äçüè´ Waiting for teacher to publish an assessment")
        st.markdown("---")
        st.markdown("### How it works:")
        st.markdown("1. üë®‚Äçüè´ Teacher generates and publishes assessment")
        st.markdown("2. ‚úçÔ∏è You attempt the questions")
        st.markdown("3. üìä Get instant detailed feedback")
        st.stop()

    tab1, tab2 = st.tabs(["‚úçÔ∏è Take Assessment", "üìä View Results"])

    with tab1:
        questions = st.session_state.questions
        q = questions[0]
        total_marks = sum(q.get('marks', 1) for q in questions)

        st.markdown(f"### üìù Assessment: {len(questions)} Questions")
        st.info(
            f"{q['board']} | Class {q['class']} | {q['subject']} "
            f"{'| ' + q['chapter'] if q['chapter'] else ''} | Total: {total_marks} marks"
        )
        st.divider()

        for idx, question in enumerate(questions, 1):
            marks = question.get('marks', 1)
            st.markdown(f"### Question {idx} [{marks} marks]")
            st.markdown(f"**{question['question']}**")
            
            # Display image if available
            images = st.session_state.get('extracted_images', [])
            if images:
                # Check if this question should have an image
                img_idx = question.get('image_index', 0)
                should_show_image = False
                
                # Check various conditions for showing image
                if question.get('has_image') or question.get('image_index') is not None:
                    should_show_image = True
                # Check if question mentions diagram/figure/image
                elif any(keyword in question.get('question', '').lower() for keyword in ['diagram', 'figure', 'image', 'observe', 'shown']):
                    should_show_image = True
                
                if should_show_image and img_idx < len(images):
                    st.image(images[img_idx], caption=f"Diagram/Image for Question {idx}", use_container_width=True)

            if question.get('ncert_reference'):
                st.info(question['ncert_reference'])

            if 'options' in question:
                current = st.session_state.student_answers.get(idx)
                option_keys = list(question['options'].keys())
                answer = st.radio(
                    "Select your answer:",
                    options=option_keys,
                    format_func=lambda x: f"{x}) {question['options'][x]}",
                    key=f"q_{idx}",
                    index=option_keys.index(current) if current in option_keys else 0
                )
                st.session_state.student_answers[idx] = answer
            elif 'labels' in question:
                # Diagram labeling question
                st.caption("üí° Label each part of the diagram")
                current = st.session_state.student_answers.get(idx, {})
                labels_dict = {}
                for label_key, label_name in question['labels'].items():
                    label_answer = st.text_input(
                        f"Label {label_key} ({label_name}):",
                        value=current.get(label_key, ""),
                        key=f"q_{idx}_label_{label_key}",
                        placeholder=f"Enter label for {label_name}"
                    )
                    labels_dict[label_key] = label_answer
                st.session_state.student_answers[idx] = labels_dict
            else:
                word_limit = question.get('word_limit', 'As required')
                st.caption(f"üìè Word Limit: {word_limit}")
                current = st.session_state.student_answers.get(idx, "")
                answer = st.text_area(
                    "Write your answer:",
                    value=current,
                    height=180,
                    key=f"q_{idx}",
                    placeholder=f"Write your answer here ({word_limit})"
                )
                st.session_state.student_answers[idx] = answer
                if answer:
                    st.caption(f"Word count: {len(answer.split())}")

            st.divider()

        answered = len(st.session_state.student_answers)
        total_q = len(questions)

        if answered < total_q:
            st.warning(f"‚ö†Ô∏è Please answer all questions ({answered}/{total_q})")

        col1, col2, col3 = st.columns([1, 1, 1])
        with col2:
            if st.button(
                "üì§ Submit Assessment",
                type="primary",
                use_container_width=True,
                disabled=(answered < total_q)
            ):
                results = []
                with st.spinner("Evaluating your answers..."):
                    for idx, question in enumerate(questions, 1):
                        student_answer = st.session_state.student_answers.get(idx, "")
                        evaluation = evaluate_answer(question, student_answer)
                        results.append({
                            'question_num': idx,
                            'question': question['question'],
                            'student_answer': student_answer,
                            'evaluation': evaluation
                        })

                score_summary = calculate_total_score(results)
                st.session_state.results = {
                    'results': results,
                    **score_summary
                }
                
                save_student_result({
                    'username': st.session_state.username,
                    'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                    'total_score': score_summary['total_score'],
                    'max_score': score_summary['max_score'],
                    'percentage': score_summary['percentage'],
                    'num_questions': len(questions)
                })
                
                st.success("‚úÖ Assessment submitted!")
                time.sleep(1)
                st.rerun()

    with tab2:
        if st.session_state.results:
            results = st.session_state.results
            st.markdown("## üìä Your Assessment Results")

            col1, col2, col3 = st.columns(3)
            col1.metric(
                "Total Score",
                f"{results['total_score']:.1f} / {results['max_score']}"
            )
            col2.metric(
                "Percentage",
                f"{results['percentage']:.1f}%"
            )

            perc = results['percentage']
            if perc >= 90:
                grade = "A+"
            elif perc >= 80:
                grade = "A"
            elif perc >= 70:
                grade = "B+"
            elif perc >= 60:
                grade = "B"
            elif perc >= 50:
                grade = "C"
            else:
                grade = "D"

            col3.metric("Grade", grade)

            if perc >= 80:
                st.success("üåü Excellent performance!")
            elif perc >= 60:
                st.info("üëç Good work. Review feedback to improve")
            else:
                st.warning("üìö Keep practicing and revise concepts")

            st.divider()
            st.subheader("Detailed Question-wise Feedback")

            for result in results['results']:
                eval_data = result['evaluation']
                score = eval_data['score']
                max_score = eval_data['max_score']

                with st.expander(
                    f"Question {result['question_num']} - {score:.1f}/{max_score} marks",
                    expanded=(score < max_score * 0.6)
                ):
                    st.markdown(f"**Question:** {result['question']}")
                    st.markdown(f"**Your Answer:** {result['student_answer']}")

                    if 'matched_points' in eval_data:
                        col_a, col_b = st.columns(2)
                        with col_a:
                            if eval_data.get('matched_points'):
                                st.markdown("‚úÖ **Points Covered**")
                                for point in eval_data['matched_points']:
                                    st.markdown(f"- {point}")
                        with col_b:
                            if eval_data.get('missing_points'):
                                st.markdown("‚ùå **Points Missed**")
                                for point in eval_data['missing_points']:
                                    st.markdown(f"- {point}")
                    elif 'matched_labels' in eval_data:
                        col_a, col_b = st.columns(2)
                        with col_a:
                            if eval_data.get('matched_labels'):
                                st.markdown("‚úÖ **Correct Labels**")
                                for label in eval_data['matched_labels']:
                                    st.markdown(f"- {label}")
                        with col_b:
                            if eval_data.get('missing_labels'):
                                st.markdown("‚ùå **Incorrect/Missing Labels**")
                                for label in eval_data['missing_labels']:
                                    st.markdown(f"- {label}")

                    st.info(f"üí° **Feedback:** {eval_data['feedback']}")

            st.divider()
            col1, col2 = st.columns(2)
            with col1:
                if st.button("üîÑ Retake Assessment", use_container_width=True):
                    st.session_state.results = None
                    st.session_state.student_answers = {}
                    st.rerun()
            with col2:
                if st.button("‚è≥ Wait for New Assessment", use_container_width=True):
                    st.session_state.questions = []
                    st.session_state.results = None
                    st.session_state.student_answers = {}
                    st.info("Check back when teacher publishes new assessment")
                    st.rerun()
        else:
            st.info("Complete the assessment to view results")

st.divider()
st.markdown(
    """
    <div style='text-align: center; color: gray; padding: 20px;'>
        <p><b>BloomSetu</b> - Aligned with Indian Curriculum</p>
    </div>
    """,
    unsafe_allow_html=True
)
